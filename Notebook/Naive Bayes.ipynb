{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotelreviews = pd.read_csv('/home/jack/code/TechLah/RevuSum/raw_data/Hotel_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hotelreviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515738 entries, 0 to 515737\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   Hotel_Address                               515738 non-null  object \n",
      " 1   Additional_Number_of_Scoring                515738 non-null  int64  \n",
      " 2   Review_Date                                 515738 non-null  object \n",
      " 3   Average_Score                               515738 non-null  float64\n",
      " 4   Hotel_Name                                  515738 non-null  object \n",
      " 5   Reviewer_Nationality                        515738 non-null  object \n",
      " 6   Negative_Review                             515738 non-null  object \n",
      " 7   Review_Total_Negative_Word_Counts           515738 non-null  int64  \n",
      " 8   Total_Number_of_Reviews                     515738 non-null  int64  \n",
      " 9   Positive_Review                             515738 non-null  object \n",
      " 10  Review_Total_Positive_Word_Counts           515738 non-null  int64  \n",
      " 11  Total_Number_of_Reviews_Reviewer_Has_Given  515738 non-null  int64  \n",
      " 12  Reviewer_Score                              515738 non-null  float64\n",
      " 13  Tags                                        515738 non-null  object \n",
      " 14  days_since_review                           515738 non-null  object \n",
      " 15  lat                                         512470 non-null  float64\n",
      " 16  lng                                         512470 non-null  float64\n",
      "dtypes: float64(4), int64(5), object(8)\n",
      "memory usage: 66.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#Using preprocessing from previous assignment\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # you can also choose other languages\n",
    "\n",
    "def preprocessing_stopwords(sentence):\n",
    "    sentence = sentence.strip(\"\") #whitespace\n",
    "    sentence = sentence.lower() #lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) #remove number\n",
    "    for punctuation in string.punctuation: #remove punc\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    \n",
    "    stopwords_removed = [w for w in word_tokens if not w in stop_words] \n",
    "        # Lemmatizing the verbs\n",
    "    verb_lemmatized = [                  \n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "        for word in stopwords_removed]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [                 \n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "        for word in verb_lemmatized]\n",
    "    \n",
    "    return noun_lemmatized\n",
    "\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sentence = sentence.strip(\"\") #whitespace\n",
    "    sentence = sentence.lower() #lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) #remove number\n",
    "    for punctuation in string.punctuation: #remove punc\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "\n",
    "        # Lemmatizing the verbs\n",
    "    verb_lemmatized = [                  \n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "        for word in word_tokens]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [                 \n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "        for word in verb_lemmatized]\n",
    "    \n",
    "    #join_list = ' '.join(noun_lemmatized)\n",
    "    \n",
    "    return noun_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_review = df.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1), (10000, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying preprocessing on the both positive and negative reviews\n",
    "\n",
    "clean_negative_review = []\n",
    "cleaned_positive_review = []\n",
    "\n",
    "\n",
    "for sentence in filtered_review.Negative_Review:\n",
    "    clean_negative_review.append(preprocessing(sentence))\n",
    "\n",
    "clean_negative_df = pd.DataFrame({'Review': clean_negative_review})    \n",
    "clean_negative_df['Review'] = clean_negative_df['Review'].astype(str)\n",
    "\n",
    "\n",
    "for sentence in filtered_review.Positive_Review:\n",
    "    cleaned_positive_review.append(preprocessing(sentence))\n",
    "    \n",
    "clean_positive_df = pd.DataFrame({'Review': cleaned_positive_review})    \n",
    "clean_positive_df['Review'] = clean_positive_df['Review'].astype(str)\n",
    "\n",
    "clean_negative_df.shape,clean_positive_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1), (10000, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying preprocessing on the both positive and negative reviews\n",
    "\n",
    "clean_negative_review = []\n",
    "cleaned_positive_review = []\n",
    "\n",
    "\n",
    "for sentence in filtered_review.Negative_Review:\n",
    "    clean_negative_review.append(preprocessing(sentence))\n",
    "\n",
    "clean_negative_df = pd.DataFrame({'Review': clean_negative_review})    \n",
    "clean_negative_df['Review'] = clean_negative_df['Review'].astype(str)\n",
    "\n",
    "\n",
    "for sentence in filtered_review.Positive_Review:\n",
    "    cleaned_positive_review.append(preprocessing(sentence))\n",
    "    \n",
    "clean_positive_df = pd.DataFrame({'Review': cleaned_positive_review})    \n",
    "clean_positive_df['Review'] = clean_positive_df['Review'].astype(str)\n",
    "\n",
    "clean_negative_df.shape,clean_positive_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    10000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of rows in the DataFrame\n",
    "num_negative_rows = clean_negative_df.shape[0]\n",
    "num_positive_rows = clean_positive_df.shape[0]\n",
    "\n",
    "# Create a new column with all 0 and 1 values based on positive/ negative\n",
    "clean_negative_df['Label'] = [0] * num_negative_rows\n",
    "clean_positive_df['Label'] = [1] * num_positive_rows\n",
    "\n",
    "clean_negative_df.head(2),clean_positive_df.head(2)\n",
    "#Combine both dataframe together to form dataset\n",
    "combined_df = pd.concat([clean_negative_df, clean_positive_df], axis=0, join='inner')\n",
    "\n",
    "combined_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = combined_df['Review']\n",
    "y = combined_df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, shuffle=True,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the 'clean_text' column\n",
    "features = vectorizer.fit_transform(combined_df.Review)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame with the features as column names\n",
    "X_bow = pd.DataFrame(features.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Score = 0.9323\n",
      "Best params = {'countvectorizer__ngram_range': (1, 2), 'multinomialnb__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature/Target\n",
    "X = X_bow\n",
    "y = combined_df['Label']\n",
    "\n",
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Define the grid of parameters\n",
    "parameters = {\n",
    "    'countvectorizer__ngram_range': ((1,2), (3,4)),\n",
    "    'multinomialnb__alpha': (0.1,1)\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_naive_bayes,\n",
    "    parameters,\n",
    "    scoring = \"recall\",\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(combined_df['Review'],combined_df['Label'])\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score = {grid_search.best_score_}\")\n",
    "\n",
    "# Best params\n",
    "print(f\"Best params = {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "naivebayes = MultinomialNB(alpha=1)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform the 'clean_text' column\n",
    "features = vectorizer.fit_transform(combined_df.Review)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame with the features as column names\n",
    "X_bow = pd.DataFrame(features.toarray(), columns=feature_names)\n",
    "\n",
    "cv_nb = cross_validate(\n",
    "    naivebayes,\n",
    "    X_bow,\n",
    "    combined_df['Label'],\n",
    "    scoring = \"accuracy\",\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "round(cv_nb['test_score'].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_test = \"Great room and the view was amazing. The buffet breakfast had so many options and so much of everything as well. \\\n",
    "    The shops under the hotel were really good and also lots of little eating places too.\\\n",
    "        Raffles is a few mins walk and you can walk to Clarke Quay as well.\\\n",
    "            Perfect location and would highly recommend.\"\n",
    "            \n",
    "Bad_test = \"the view was horrible. breakfast had so little options and so little of everything. \\\n",
    "    The shops under the hotel were really terrible and very little eating places too.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12675014e-20 1.00000000e+00]] [1]\n"
     ]
    }
   ],
   "source": [
    "pipeline_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1, 2)),\n",
    "    MultinomialNB(alpha=1)\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_naive_bayes.fit(combined_df['Review'], combined_df['Label'])\n",
    "\n",
    "# Now the model is trained and ready for predictions\n",
    "\n",
    "# Prepare the input text for prediction\n",
    "input_text = \"This is a great product!\"\n",
    "\n",
    "# Make predictions using the trained pipeline\n",
    "predictions = pipeline_naive_bayes.predict_proba([Good_test])\n",
    "prediction_label = pipeline_naive_bayes.predict([Good_test])\n",
    "\n",
    "print(predictions,prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.12675014e-20,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
